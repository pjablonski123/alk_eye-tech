{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eva-alk-p1",
      "provenance": [],
      "mount_file_id": "1WtcXGZobVoQKAOrrx5amxD0mD1fRfnNa",
      "authorship_tag": "ABX9TyMXfNgq7Vb5tFvurmYpX2LJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjablonski123/alk_eye-tech/blob/master/eva_alk_p1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clh5cxfJ3RHq",
        "colab_type": "code",
        "outputId": "35be301e-d11f-45bd-f6c3-d17c86ed9152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras.applications.inception_v3 import InceptionV3 \n",
        "from keras.layers import Dense, GlobalAveragePooling2D \n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.models import Model \n",
        "from keras import optimizers \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "from keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_4Q70Ly3Wlf",
        "colab_type": "code",
        "outputId": "31a8c590-8f08-4139-d9b9-5bb7f5d285f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/content/drive/My Drive/TEST1'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TEST1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbkuPZQGvEPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03865be6-f667-452b-b206-c1f2879455d3"
      },
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=True)\n",
        "base_model.summary()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 2s 0us/step\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,851,784\n",
            "Trainable params: 23,817,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq0jL2uEe3nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre-trained Inception V3 model \n",
        "base_model = InceptionV3(weights='imagenet', include_top=False) \n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output \n",
        "\n",
        "x = GlobalAveragePooling2D()(x) \n",
        "x = Dense(64, activation='relu')(x) \n",
        "predictions = Dense(2, activation='softmax')(x) \n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions) \n",
        "\n",
        "model.trainable = True\n",
        "\n",
        "adam = optimizers.adam(lr=0.01)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVig2h_-9E36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) \n",
        "test_datagen = ImageDataGenerator(rescale=1./255) \n",
        "train_dir = '/content/drive/My Drive/TEST1/' \n",
        "test_dir = '/content/drive/My Drive/TEST2/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYWEYv5n9alC",
        "colab_type": "code",
        "outputId": "8b7d49da-7e7d-49b7-a62b-1f10d7316820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory( train_dir,\n",
        "  target_size=(299, 299), batch_size=10, class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory( test_dir,\n",
        "  target_size=(299, 299), batch_size=10, class_mode='categorical')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 500 images belonging to 2 classes.\n",
            "Found 31 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3VZpDeDIujA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup a callback to save the best model \n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\n",
        "  'model.{epoch:02d}-{val_accuracy:.2f}.hdf5', \n",
        "  monitor='val_accuracy', verbose=1, save_best_only=True, \n",
        "  mode='max', period=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAyz__fzLQET",
        "colab_type": "code",
        "outputId": "fab3fb02-31f9-4429-c450-8233f6888f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(train_generator, verbose=1, \n",
        "  steps_per_epoch=len(train_generator), epochs=100,\n",
        "  validation_data=test_generator,\n",
        "  validation_steps=len(test_generator), callbacks=callbacks)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 331s 7s/step - loss: 1.0076 - accuracy: 0.5180 - val_loss: 821960114176.0000 - val_accuracy: 0.5484\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.54839, saving model to model.01-0.55.hdf5\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 14s 289ms/step - loss: 0.6989 - accuracy: 0.4980 - val_loss: 2776586.5000 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.54839\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 14s 284ms/step - loss: 0.6766 - accuracy: 0.5400 - val_loss: 0.0000e+00 - val_accuracy: 0.5484\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.54839\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.6598 - accuracy: 0.6040 - val_loss: 0.0000e+00 - val_accuracy: 0.5161\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.54839\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.6128 - accuracy: 0.6780 - val_loss: 0.3264 - val_accuracy: 0.6129\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.54839 to 0.61290, saving model to model.05-0.61.hdf5\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.5243 - accuracy: 0.7540 - val_loss: 0.4592 - val_accuracy: 0.5484\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.61290\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.4472 - accuracy: 0.8160 - val_loss: 1.3832 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.61290\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 14s 284ms/step - loss: 0.4649 - accuracy: 0.8180 - val_loss: 1.0265 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.61290\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.4794 - accuracy: 0.8080 - val_loss: 1720.4365 - val_accuracy: 0.5484\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.61290\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.3840 - accuracy: 0.8380 - val_loss: 2.3381 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.61290\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.3703 - accuracy: 0.8660 - val_loss: 3.5015 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.61290\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.3006 - accuracy: 0.9040 - val_loss: 0.0828 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.61290\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3384 - accuracy: 0.8840 - val_loss: 0.0802 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.61290\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2651 - accuracy: 0.9140 - val_loss: 2.6090 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.61290\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.3106 - accuracy: 0.8820 - val_loss: 139.4896 - val_accuracy: 0.5806\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.61290\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.3267 - accuracy: 0.8820 - val_loss: 0.0000e+00 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.61290 to 0.74194, saving model to model.16-0.74.hdf5\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 14s 284ms/step - loss: 0.2303 - accuracy: 0.9320 - val_loss: 0.0284 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.74194\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2486 - accuracy: 0.9120 - val_loss: 0.0660 - val_accuracy: 0.5484\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.74194\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1918 - accuracy: 0.9440 - val_loss: 0.0151 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.74194\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1753 - accuracy: 0.9400 - val_loss: 3.7451 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.74194\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.2993 - accuracy: 0.8700 - val_loss: 0.0574 - val_accuracy: 0.8387\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.74194 to 0.83871, saving model to model.21-0.84.hdf5\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.2292 - accuracy: 0.9200 - val_loss: 3.8827 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.83871\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1941 - accuracy: 0.9360 - val_loss: 0.0243 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.83871\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.1574 - accuracy: 0.9400 - val_loss: 1.7921 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.83871\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.1459 - accuracy: 0.9420 - val_loss: 0.7945 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.83871 to 0.87097, saving model to model.25-0.87.hdf5\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.1949 - accuracy: 0.9260 - val_loss: 4.1085 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87097\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.1320 - accuracy: 0.9520 - val_loss: 3.3026 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87097\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1428 - accuracy: 0.9540 - val_loss: 0.0267 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.87097\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0774 - accuracy: 0.9780 - val_loss: 0.0103 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87097\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1696 - accuracy: 0.9340 - val_loss: 4.4023 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87097\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.1240 - accuracy: 0.9560 - val_loss: 0.0072 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.87097 to 0.93548, saving model to model.31-0.94.hdf5\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0815 - accuracy: 0.9720 - val_loss: 0.0052 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.93548\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0926 - accuracy: 0.9660 - val_loss: 5.5343 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.93548\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0742 - accuracy: 0.9720 - val_loss: 4.1228 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.93548\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0918 - accuracy: 0.9720 - val_loss: 0.0061 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.93548\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1256 - accuracy: 0.9600 - val_loss: 0.0119 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.93548\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1272 - accuracy: 0.9660 - val_loss: 0.0030 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.93548\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1841 - accuracy: 0.9400 - val_loss: 4.1420 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.93548\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0801 - accuracy: 0.9760 - val_loss: 4.9431 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.93548\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0651 - accuracy: 0.9760 - val_loss: 0.0047 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.93548\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0412 - accuracy: 0.9800 - val_loss: 0.0000e+00 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.93548\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0735 - accuracy: 0.9800 - val_loss: 0.0102 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.93548\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0790 - accuracy: 0.9760 - val_loss: 0.0065 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.93548\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0343 - accuracy: 0.9920 - val_loss: 5.5634 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.93548\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 3.3497e-05 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.93548\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0773 - accuracy: 0.9720 - val_loss: 0.0000e+00 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.93548\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1072 - accuracy: 0.9600 - val_loss: 0.0094 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.93548\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0823 - accuracy: 0.9680 - val_loss: 0.0048 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.93548\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0537 - accuracy: 0.9820 - val_loss: 0.0051 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.93548\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.93548\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 9.3345e-04 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.93548\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.1673 - accuracy: 0.9600 - val_loss: 6.1688 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.93548\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0584 - accuracy: 0.9840 - val_loss: 0.0060 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.93548\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0660 - accuracy: 0.9760 - val_loss: 0.0047 - val_accuracy: 0.8387\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.93548\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0680 - accuracy: 0.9800 - val_loss: 5.3711 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.93548\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0452 - accuracy: 0.9860 - val_loss: 0.0015 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.93548\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 14s 276ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0112 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.93548\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.93548\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 7.4777 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.93548\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0355 - accuracy: 0.9880 - val_loss: 9.7644e-04 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.93548\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.1131 - accuracy: 0.9540 - val_loss: 0.0183 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.93548\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0748 - accuracy: 0.9740 - val_loss: 0.0065 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.93548\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0768 - accuracy: 0.9760 - val_loss: 0.0104 - val_accuracy: 0.6129\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.93548\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0569 - accuracy: 0.9760 - val_loss: 5.5039 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.93548\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0372 - accuracy: 0.9900 - val_loss: 4.0211 - val_accuracy: 0.7742\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.93548\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0577 - accuracy: 0.9800 - val_loss: 0.0020 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.93548\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0221 - accuracy: 0.9940 - val_loss: 6.6541 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.93548\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.0000e+00 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.93548\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0454 - accuracy: 0.9760 - val_loss: 4.8628 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93548\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0390 - accuracy: 0.9900 - val_loss: 5.3555 - val_accuracy: 0.5806\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.93548\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.93548\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 7.3203e-04 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.93548\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 2.9802e-06 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.93548\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 6.5556e-04 - val_accuracy: 0.7097\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93548\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 9.1237e-04 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.93548\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 8.0123 - val_accuracy: 0.8387\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.93548\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0541 - accuracy: 0.9840 - val_loss: 0.0013 - val_accuracy: 0.6774\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.93548\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0721 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.93548\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.5889e-04 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.93548\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 8.9097e-04 - accuracy: 1.0000 - val_loss: 2.6556e-04 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.93548\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4256e-04 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.93548\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 8.5158e-04 - accuracy: 1.0000 - val_loss: 1.8643e-04 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.93548\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0027 - accuracy: 0.9980 - val_loss: 4.9615e-04 - val_accuracy: 0.4839\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93548\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.1223 - accuracy: 0.9660 - val_loss: 0.0000e+00 - val_accuracy: 0.6129\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.93548\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0407 - accuracy: 0.9920 - val_loss: 5.6538 - val_accuracy: 0.8387\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.93548\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0325 - accuracy: 0.9880 - val_loss: 5.7008 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.93548\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0876 - accuracy: 0.9660 - val_loss: 5.1658 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.93548\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 14s 276ms/step - loss: 0.1143 - accuracy: 0.9560 - val_loss: 4.3134 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.93548\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 14s 276ms/step - loss: 0.0280 - accuracy: 0.9960 - val_loss: 0.0026 - val_accuracy: 0.5161\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.93548\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0407 - accuracy: 0.9920 - val_loss: 0.0468 - val_accuracy: 0.6774\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93548\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0100 - val_accuracy: 0.7419\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93548\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0244 - accuracy: 0.9880 - val_loss: 5.5724 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93548\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0857 - accuracy: 0.9780 - val_loss: 6.1020 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93548\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 0.0012 - val_accuracy: 0.4516\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93548\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0214 - accuracy: 0.9920 - val_loss: 6.1934e-04 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93548\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.0000e+00 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93548\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93548\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93548\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 5.5556e-04 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93548\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 14s 276ms/step - loss: 9.7294e-04 - accuracy: 1.0000 - val_loss: 7.4741e-05 - val_accuracy: 0.8065\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K59QtXezLV7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "bcf68fa1-5870-4f5f-c4ab-24b50c8a8220"
      },
      "source": [
        "def plot_history(history): \n",
        "    acc = history.history['accuracy'] \n",
        "    val_acc = history.history['val_accuracy'] \n",
        "    loss = history.history['loss'] \n",
        "    val_loss = history.history['val_loss'] \n",
        "    epochs = range(1, len(acc) + 1) \n",
        "    \n",
        "    plt.figure() \n",
        "    plt.title('Training and validation accuracy') \n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', color='red', \\\n",
        "      label='Validation acc') \n",
        "    plt.legend() \n",
        "    plt.show() \n",
        "   \n",
        "    plt.figure() \n",
        "    plt.title('Training and validation loss')\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', color='red', \\\n",
        "      label='Validation loss') \n",
        "    plt.legend() \n",
        "    plt.show() \n",
        "    return acc, val_acc, loss, val_loss \n",
        "\n",
        "acc, val_acc, loss, val_loss = plot_history(history)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs6ckcFQLl6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e22d370-d653-44de-f799-18cf26e1d480"
      },
      "source": [
        "cd '/content/drive/My Drive/TEST1'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TEST1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWfDktW-nOal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('model.31-0.94.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTvRL0NlnzxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0de7e159-3fce-46ea-a6a7-73094f47e625"
      },
      "source": [
        "model = load_model('model.01-0.67.hdf5')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "  warnings.warn('Error in loading the saved optimizer '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBLZs1kMnaC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['CNV',  'NORMAL']\n",
        "\n",
        "def preprocess_input(x):\n",
        "    x = img_to_array(x) / 255.\n",
        "    return np.expand_dims(x, axis=0) \n",
        "\n",
        "# Prediction for an image path in the local directory\n",
        "def predict_from_image_path(image_path):\n",
        "    return predict_image(load_img(image_path, target_size=(299, 299)))\n",
        "\n",
        "# Prediction for an image URL path\n",
        "def predict_from_image_url(image_url):\n",
        "    res = requests.get(image_url)\n",
        "    im = Image.open(BytesIO(res.content))\n",
        "    return predict_from_image_path(im.fp)\n",
        "    \n",
        "# Predict an image\n",
        "def predict_image(im):\n",
        "    x = preprocess_input(im)\n",
        "    pred = np.argmax(model.predict(x))\n",
        "    return pred, classes[pred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHQXkyXhnPtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd70bd5b-7ced-4df1-ed2c-29c223d1e370"
      },
      "source": [
        "#Picture with CNV\n",
        "print(predict_from_image_path('/content/drive/My Drive/TEST2/CNV/test2c.jpeg'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 'CNV')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmk73ohjoG1Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8345245-4479-4fdc-d81c-1bbda05c2973"
      },
      "source": [
        "#Picture without an eye disease\n",
        "print(predict_from_image_path('/content/drive/My Drive/TEST2/CNV/test1n.jpeg'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 'NORMAL')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syZs5i1iqTN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b8442da-1684-41b4-a1f9-6e78307c8f95"
      },
      "source": [
        "#CNV again\n",
        "print(predict_from_image_path('/content/drive/My Drive/TEST2/CNV/no-disease-cnv-28682-8.jpeg'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 'CNV')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sR10KOaqlf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}